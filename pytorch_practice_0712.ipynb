{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "6stJNEcp-N6q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de902934-7ecb-48a8-e2c0-a33914fb43e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torchvision.datasets.mnist import MNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "training_data = MNIST(root=\"./\", train=True, download=True, transform=ToTensor())\n",
        "test_data = MNIST(root=\"./\", train=False, download=True, transform=ToTensor())\n",
        "\n",
        "print(len(training_data))\n",
        "print(len(test_data))\n",
        "\n",
        "for i in range(9):\n",
        "  plt.subplot(3,3,i+1)\n",
        "  plt.imshow(training_data.data[i])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aa_GL2JCKSPX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6d8b85ec-b082-407f-c548-dfa0814d10d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:02<00:00, 4506669.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 134089.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:01<00:00, 1089904.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 5300647.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "60000\n",
            "10000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data.dataloader import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=32, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "KjsoZW8ZLMwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3):\n",
        "        super(BasicBlock, self).__init__()\n",
        "\n",
        "        # 합성곱층 정의하기\n",
        "        self.c1 = nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=1)\n",
        "        self.c2 = nn.Conv2d(out_channels, out_channels, kernel_size, stride=1, padding=1)\n",
        "\n",
        "        # 배치 정규화층 정의\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        # 활성화 함수 정의\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        # 다운샘플 정의\n",
        "        self.downsample = None\n",
        "        if in_channels != out_channels:\n",
        "            self.downsample = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_ = x\n",
        "\n",
        "        x = self.c1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.c2(x)\n",
        "        x = self.bn2(x)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            x_ = self.downsample(x_)\n",
        "\n",
        "        x += x_\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "# ResNet 모델 정의\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "\n",
        "        self.b1 = block(in_channels=1, out_channels=64)\n",
        "        self.b2 = block(in_channels=64, out_channels=128)\n",
        "        self.b3 = block(in_channels=128, out_channels=256)\n",
        "\n",
        "        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.fc1 = nn.Linear(256 * 3 * 3, 512)  # MNIST 이미지 크기(28x28)에 따라 수정 필요\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.b1(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.b2(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.b3(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = ResNet(block=BasicBlock)\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "ur3MR6bMP4IA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94f028ee-35e2-48f6-e9fd-dd27bfebba13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (b1): BasicBlock(\n",
              "    (c1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (c2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "    (downsample): Conv2d(1, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              "  (b2): BasicBlock(\n",
              "    (c1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (c2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "    (downsample): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              "  (b3): BasicBlock(\n",
              "    (c1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (c2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "    (downsample): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "  (fc1): Linear(in_features=2304, out_features=512, bias=True)\n",
              "  (fc2): Linear(in_features=512, out_features=10, bias=True)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import Adam\n",
        "from tqdm import tqdm\n",
        "\n",
        "lr = 1e-4\n",
        "optim= Adam(model.parameters(), lr=lr)\n",
        "\n",
        "for epoch in range(10):\n",
        "  iterator = tqdm(train_dataloader)\n",
        "  for data, label in iterator:\n",
        "    optim.zero_grad()\n",
        "\n",
        "    preds = model(data.to(device))\n",
        "\n",
        "    loss = nn.CrossEntropyLoss()(preds, label.to(device))\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "\n",
        "    iterator.set_description(f\"epoch: {epoch+1} loss: {loss.item():.8f}\")\n",
        "\n",
        "torch.save(model.state_dict(), \"ResNet.pth\")"
      ],
      "metadata": {
        "id": "cbRLZVMEYpHP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40d8bf6a-fba3-48e8-a561-170a3a8d5771"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch: 1 loss: 0.00000409: 100%|██████████| 1875/1875 [00:31<00:00, 58.92it/s]\n",
            "epoch: 2 loss: 0.00001733: 100%|██████████| 1875/1875 [00:30<00:00, 61.35it/s]\n",
            "epoch: 3 loss: 0.00030322: 100%|██████████| 1875/1875 [00:30<00:00, 61.03it/s]\n",
            "epoch: 4 loss: 0.03700021: 100%|██████████| 1875/1875 [00:30<00:00, 60.80it/s]\n",
            "epoch: 5 loss: 0.00078247: 100%|██████████| 1875/1875 [00:31<00:00, 59.48it/s]\n",
            "epoch: 6 loss: 0.00000243: 100%|██████████| 1875/1875 [00:31<00:00, 60.32it/s]\n",
            "epoch: 7 loss: 0.00000078: 100%|██████████| 1875/1875 [00:31<00:00, 59.63it/s]\n",
            "epoch: 8 loss: 0.00000517: 100%|██████████| 1875/1875 [00:31<00:00, 60.31it/s]\n",
            "epoch: 9 loss: 0.00000004: 100%|██████████| 1875/1875 [00:30<00:00, 60.82it/s]\n",
            "epoch: 10 loss: 0.00000057: 100%|██████████| 1875/1875 [00:31<00:00, 60.10it/s]\n",
            "epoch: 11 loss: 0.00000473: 100%|██████████| 1875/1875 [00:31<00:00, 60.10it/s]\n",
            "epoch: 12 loss: 0.00000010: 100%|██████████| 1875/1875 [00:30<00:00, 61.63it/s]\n",
            "epoch: 13 loss: 0.00000445: 100%|██████████| 1875/1875 [00:30<00:00, 61.32it/s]\n",
            "epoch: 14 loss: 0.00026902: 100%|██████████| 1875/1875 [00:31<00:00, 59.65it/s]\n",
            "epoch: 15 loss: 0.00010090: 100%|██████████| 1875/1875 [00:31<00:00, 60.41it/s]\n",
            "epoch: 16 loss: 0.00000229: 100%|██████████| 1875/1875 [00:30<00:00, 61.05it/s]\n",
            "epoch: 17 loss: 0.00000943: 100%|██████████| 1875/1875 [00:30<00:00, 61.52it/s]\n",
            "epoch: 18 loss: 0.00053510: 100%|██████████| 1875/1875 [00:31<00:00, 59.45it/s]\n",
            "epoch: 19 loss: 0.00000672: 100%|██████████| 1875/1875 [00:31<00:00, 60.38it/s]\n",
            "epoch: 20 loss: 0.00000211: 100%|██████████| 1875/1875 [00:30<00:00, 60.92it/s]\n",
            "epoch: 21 loss: 0.00000005: 100%|██████████| 1875/1875 [00:30<00:00, 61.03it/s]\n",
            "epoch: 22 loss: 0.00002999: 100%|██████████| 1875/1875 [00:31<00:00, 60.18it/s]\n",
            "epoch: 23 loss: 0.00000444: 100%|██████████| 1875/1875 [00:31<00:00, 59.95it/s]\n",
            "epoch: 24 loss: 0.00000202: 100%|██████████| 1875/1875 [00:30<00:00, 61.34it/s]\n",
            "epoch: 25 loss: 0.00000546: 100%|██████████| 1875/1875 [00:30<00:00, 61.38it/s]\n",
            "epoch: 26 loss: 0.00000004: 100%|██████████| 1875/1875 [00:30<00:00, 60.74it/s]\n",
            "epoch: 27 loss: 0.00007186: 100%|██████████| 1875/1875 [00:31<00:00, 58.80it/s]\n",
            "epoch: 28 loss: 0.00383148: 100%|██████████| 1875/1875 [00:30<00:00, 61.15it/s]\n",
            "epoch: 29 loss: 0.00000045: 100%|██████████| 1875/1875 [00:30<00:00, 61.16it/s]\n",
            "epoch: 30 loss: 0.00000004: 100%|██████████| 1875/1875 [00:30<00:00, 61.09it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Initialize variables to track correct predictions and total predictions\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# Disable gradient calculations\n",
        "with torch.no_grad():\n",
        "    for data, labels in test_dataloader:\n",
        "        data, labels = data.to(device), labels.to(device)\n",
        "\n",
        "        # Get predictions\n",
        "        outputs = model(data)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        # Update total and correct predictions\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "# Calculate and print accuracy\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Test Accuracy: {accuracy:.2f}%')ㅌ"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WJdKgv4uQsQ",
        "outputId": "0ae3d98a-91e1-4294-8def-5e86c291f175"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 99.62%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# CIFAR-10 데이터셋에 맞춘 데이터 전처리 및 로드\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize images to [-1, 1]\n",
        "])\n",
        "\n",
        "training_data = CIFAR10(root=\"./\", train=True, download=True, transform=transform)\n",
        "test_data = CIFAR10(root=\"./\", train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "F_YlsM8t5WiC",
        "outputId": "52de50b1-5153-4529-9285-a700cfe38f23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BasicBlock 및 ResNet 모델 정의\n",
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.c1 = nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=1)\n",
        "        self.c2 = nn.Conv2d(out_channels, out_channels, kernel_size, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.downsample = None\n",
        "        if in_channels != out_channels:\n",
        "            self.downsample = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_ = x\n",
        "        x = self.c1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.c2(x)\n",
        "        x = self.bn2(x)\n",
        "        if self.downsample is not None:\n",
        "            x_ = self.downsample(x_)\n",
        "        x += x_\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.b1 = block(in_channels=3, out_channels=64)  # CIFAR-10 이미지는 3 채널(RGB)\n",
        "        self.b2 = block(in_channels=64, out_channels=128)\n",
        "        self.b3 = block(in_channels=128, out_channels=256)\n",
        "        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(256 * 4 * 4, 512)  # CIFAR-10 이미지 크기(32x32)에 따라 수정 필요\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.b1(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.b2(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.b3(x)\n",
        "        x = self.pool(x)\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "kYEEaafe6oGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 설정\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = ResNet(block=BasicBlock)\n",
        "model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "oSSHh_s1EIXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 루프\n",
        "epochs = 15\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader)}\")"
      ],
      "metadata": {
        "id": "jY6CTAQ3EKhA",
        "outputId": "a86ac884-ea31-406e-943d-5c7bcad6c695",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15, Loss: 1.212619682178473\n",
            "Epoch 2/15, Loss: 0.7075678982088328\n",
            "Epoch 3/15, Loss: 0.5051305612068042\n",
            "Epoch 4/15, Loss: 0.3685993504760515\n",
            "Epoch 5/15, Loss: 0.26080789521831993\n",
            "Epoch 6/15, Loss: 0.1732452024022103\n",
            "Epoch 7/15, Loss: 0.11347148327104499\n",
            "Epoch 8/15, Loss: 0.08288532110583752\n",
            "Epoch 9/15, Loss: 0.0631540667728933\n",
            "Epoch 10/15, Loss: 0.057868304102362406\n",
            "Epoch 11/15, Loss: 0.04792755713958479\n",
            "Epoch 12/15, Loss: 0.04770421342509787\n",
            "Epoch 13/15, Loss: 0.03469900202470274\n",
            "Epoch 14/15, Loss: 0.0334559611505275\n",
            "Epoch 15/15, Loss: 0.03997258219720267\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 평가\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Accuracy of the model on the test images: {100 * correct / total}%\")"
      ],
      "metadata": {
        "id": "_LTtchkHENXz",
        "outputId": "f767fa84-d29d-4f3a-df95-7c7976177861",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model on the test images: 84.01%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# CIFAR-10 데이터셋에 맞춘 데이터 전처리 및 로드\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize images to [-1, 1]\n",
        "])\n",
        "\n",
        "training_data = CIFAR10(root=\"./\", train=True, download=True, transform=transform)\n",
        "test_data = CIFAR10(root=\"./\", train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
        "\n",
        "# BasicBlock 및 ResNet 모델 정의\n",
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.c1 = nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=1)\n",
        "        self.c2 = nn.Conv2d(out_channels, out_channels, kernel_size, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.downsample = None\n",
        "        if in_channels != out_channels:\n",
        "            self.downsample = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_ = x\n",
        "        x = self.c1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.c2(x)\n",
        "        x = self.bn2(x)\n",
        "        if self.downsample is not None:\n",
        "            x_ = self.downsample(x_)\n",
        "        x += x_\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.b1 = block(in_channels=3, out_channels=64)  # CIFAR-10 이미지는 3 채널(RGB)\n",
        "        self.b2 = block(in_channels=64, out_channels=128)\n",
        "        self.b3 = block(in_channels=128, out_channels=256)\n",
        "        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(256 * 4 * 4, 512)  # CIFAR-10 이미지 크기(32x32)에 따라 수정 필요\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.b1(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.b2(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.b3(x)\n",
        "        x = self.pool(x)\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# 학습 설정\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = ResNet(block=BasicBlock)\n",
        "model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)  # 스케줄러 초기화\n",
        "\n",
        "# 학습 루프\n",
        "epochs = 15\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # 학습률 업데이트\n",
        "    scheduler.step()\n",
        "\n",
        "    # 현재 학습률 출력\n",
        "    current_lr = scheduler.get_last_lr()[0]\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader)}, Learning Rate: {current_lr}\")\n",
        "\n",
        "# 모델 평가\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Accuracy of the model on the test images: {100 * correct / total}%\")"
      ],
      "metadata": {
        "id": "L6Dsd5OIHnNL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6638aa8a-95a6-4018-a361-7593586075a5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:03<00:00, 42912174.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./cifar-10-python.tar.gz to ./\n",
            "Files already downloaded and verified\n",
            "Epoch 1/15, Loss: 1.3922769870904401, Learning Rate: 0.001\n",
            "Epoch 2/15, Loss: 0.9084739969362079, Learning Rate: 0.001\n",
            "Epoch 3/15, Loss: 0.7043208841548856, Learning Rate: 0.001\n",
            "Epoch 4/15, Loss: 0.5824587398096729, Learning Rate: 0.001\n",
            "Epoch 5/15, Loss: 0.4964034835929456, Learning Rate: 0.001\n",
            "Epoch 6/15, Loss: 0.4371373100239602, Learning Rate: 0.001\n",
            "Epoch 7/15, Loss: 0.3926087353292786, Learning Rate: 0.001\n",
            "Epoch 8/15, Loss: 0.3506616155433533, Learning Rate: 0.001\n",
            "Epoch 9/15, Loss: 0.31320518678259057, Learning Rate: 0.001\n",
            "Epoch 10/15, Loss: 0.2870209834936177, Learning Rate: 0.0001\n",
            "Epoch 11/15, Loss: 0.19574125575573395, Learning Rate: 0.0001\n",
            "Epoch 12/15, Loss: 0.1658977996772322, Learning Rate: 0.0001\n",
            "Epoch 13/15, Loss: 0.1526244363254484, Learning Rate: 0.0001\n",
            "Epoch 14/15, Loss: 0.1430547961684139, Learning Rate: 0.0001\n",
            "Epoch 15/15, Loss: 0.13422542554624092, Learning Rate: 0.0001\n",
            "Accuracy of the model on the test images: 89.46%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# CIFAR-10 데이터셋에 맞춘 데이터 전처리 및 로드\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize images to [-1, 1]\n",
        "])\n",
        "\n",
        "training_data = CIFAR10(root=\"./\", train=True, download=True, transform=transform)\n",
        "test_data = CIFAR10(root=\"./\", train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
        "\n",
        "# BasicBlock 및 ResNet 모델 정의\n",
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.c1 = nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=1)\n",
        "        self.c2 = nn.Conv2d(out_channels, out_channels, kernel_size, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.downsample = None\n",
        "        if in_channels != out_channels:\n",
        "            self.downsample = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_ = x\n",
        "        x = self.c1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.c2(x)\n",
        "        x = self.bn2(x)\n",
        "        if self.downsample is not None:\n",
        "            x_ = self.downsample(x_)\n",
        "        x += x_\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.b1 = block(in_channels=3, out_channels=64)  # CIFAR-10 이미지는 3 채널(RGB)\n",
        "        self.b2 = block(in_channels=64, out_channels=128)  # 레이어 2에 추가된 블록\n",
        "        self.b3 = block(in_channels=128, out_channels=128)  # 레이어 2에 추가된 블록\n",
        "        self.b4 = block(in_channels=128, out_channels=256)  # 레이어 3에 추가된 블록\n",
        "        self.b5 = block(in_channels=256, out_channels=256)  # 레이어 3에 추가된 블록\n",
        "        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(256 * 4 * 4, 512)  # CIFAR-10 이미지 크기(32x32)에 따라 수정 필요\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.b1(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.b2(x)  # 레이어 2에서 추가된 블록\n",
        "        x = self.b3(x)  # 레이어 2에서 추가된 블록\n",
        "        x = self.pool(x)\n",
        "        x = self.b4(x)  # 레이어 3에서 추가된 블록\n",
        "        x = self.b5(x)  # 레이어 3에서 추가된 블록\n",
        "        x = self.pool(x)\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# 학습 설정\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = ResNet(block=BasicBlock)\n",
        "model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)  # 스케줄러 초기화\n",
        "\n",
        "# 학습 루프\n",
        "epochs = 15\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # 학습률 업데이트\n",
        "    scheduler.step()\n",
        "\n",
        "    # 현재 학습률 출력\n",
        "    current_lr = scheduler.get_last_lr()[0]\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader)}, Learning Rate: {current_lr}\")\n",
        "\n",
        "# 모델 평가\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Accuracy of the model on the test images: {100 * correct / total}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g11_4ouxSxD6",
        "outputId": "a0f44aa9-84b8-4a1d-a650-b58b61681008"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Epoch 1/15, Loss: 1.5558335701827808, Learning Rate: 0.001\n",
            "Epoch 2/15, Loss: 1.1001707856612437, Learning Rate: 0.001\n",
            "Epoch 3/15, Loss: 0.8886599015930424, Learning Rate: 0.001\n",
            "Epoch 4/15, Loss: 0.7483946900919575, Learning Rate: 0.001\n",
            "Epoch 5/15, Loss: 0.6532728075600036, Learning Rate: 0.001\n",
            "Epoch 6/15, Loss: 0.5657970766963252, Learning Rate: 0.001\n",
            "Epoch 7/15, Loss: 0.5092005751207661, Learning Rate: 0.001\n",
            "Epoch 8/15, Loss: 0.45165437301787575, Learning Rate: 0.001\n",
            "Epoch 9/15, Loss: 0.41626235697885305, Learning Rate: 0.001\n",
            "Epoch 10/15, Loss: 0.38470886330432297, Learning Rate: 0.0001\n",
            "Epoch 11/15, Loss: 0.26826154927501594, Learning Rate: 0.0001\n",
            "Epoch 12/15, Loss: 0.23885303263164237, Learning Rate: 0.0001\n",
            "Epoch 13/15, Loss: 0.226880258068328, Learning Rate: 0.0001\n",
            "Epoch 14/15, Loss: 0.21356941322746026, Learning Rate: 0.0001\n",
            "Epoch 15/15, Loss: 0.2055493156375635, Learning Rate: 0.0001\n",
            "Accuracy of the model on the test images: 89.28%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# CIFAR-10 데이터셋에 맞춘 데이터 전처리 및 로드\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize images to [-1, 1]\n",
        "])\n",
        "\n",
        "training_data = CIFAR10(root=\"./\", train=True, download=True, transform=transform)\n",
        "test_data = CIFAR10(root=\"./\", train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
        "\n",
        "# BasicBlock 및 ResNet 모델 정의\n",
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.c1 = nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)  # 배치 정규화 추가\n",
        "        self.c2 = nn.Conv2d(out_channels, out_channels, kernel_size, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)  # 배치 정규화 추가\n",
        "        self.relu = nn.ReLU()\n",
        "        self.downsample = None\n",
        "        if in_channels != out_channels:\n",
        "            self.downsample = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1)\n",
        "            self.bn_downsample = nn.BatchNorm2d(out_channels)  # 배치 정규화 추가\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_ = x\n",
        "        x = self.c1(x)\n",
        "        x = self.bn1(x)  # 배치 정규화 적용\n",
        "        x = self.relu(x)\n",
        "        x = self.c2(x)\n",
        "        x = self.bn2(x)  # 배치 정규화 적용\n",
        "        if self.downsample is not None:\n",
        "            x_ = self.downsample(x_)\n",
        "            x_ = self.bn_downsample(x_)  # 배치 정규화 적용\n",
        "        x += x_\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.b1 = block(in_channels=3, out_channels=64)  # CIFAR-10 이미지는 3 채널(RGB)\n",
        "        self.b2 = block(in_channels=64, out_channels=128)  # 레이어 2에 추가된 블록\n",
        "        self.b3 = block(in_channels=128, out_channels=128)  # 레이어 2에 추가된 블록\n",
        "        self.b4 = block(in_channels=128, out_channels=256)  # 레이어 3에 추가된 블록\n",
        "        self.b5 = block(in_channels=256, out_channels=256)  # 레이어 3에 추가된 블록\n",
        "        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(256 * 4 * 4, 512)  # CIFAR-10 이미지 크기(32x32)에 따라 수정 필요\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.b1(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.b2(x)  # 레이어 2에서 추가된 블록\n",
        "        x = self.b3(x)  # 레이어 2에서 추가된 블록\n",
        "        x = self.pool(x)\n",
        "        x = self.b4(x)  # 레이어 3에서 추가된 블록\n",
        "        x = self.b5(x)  # 레이어 3에서 추가된 블록\n",
        "        x = self.pool(x)\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# 학습 설정\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = ResNet(block=BasicBlock)\n",
        "model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)  # 스케줄러 초기화\n",
        "\n",
        "# 학습 루프\n",
        "epochs = 15\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # 학습률 업데이트\n",
        "    scheduler.step()\n",
        "\n",
        "    # 현재 학습률 출력\n",
        "    current_lr = scheduler.get_last_lr()[0]\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader)}, Learning Rate: {current_lr}\")\n",
        "\n",
        "# 모델 평가\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Accuracy of the model on the test images: {100 * correct / total}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UA-8iMltV03Z",
        "outputId": "af4d5984-2534-490c-cd04-ef542771d1d1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Epoch 1/15, Loss: 1.4992169061737597, Learning Rate: 0.001\n",
            "Epoch 2/15, Loss: 1.0576794568230123, Learning Rate: 0.001\n",
            "Epoch 3/15, Loss: 0.84558966755867, Learning Rate: 0.001\n",
            "Epoch 4/15, Loss: 0.7044079229807305, Learning Rate: 0.001\n",
            "Epoch 5/15, Loss: 0.6011244706104478, Learning Rate: 0.001\n",
            "Epoch 6/15, Loss: 0.5197887662655253, Learning Rate: 0.001\n",
            "Epoch 7/15, Loss: 0.4639984415582074, Learning Rate: 0.001\n",
            "Epoch 8/15, Loss: 0.4113897891605602, Learning Rate: 0.001\n",
            "Epoch 9/15, Loss: 0.3774785412489758, Learning Rate: 0.001\n",
            "Epoch 10/15, Loss: 0.34278856063514107, Learning Rate: 0.0001\n",
            "Epoch 11/15, Loss: 0.23151218786340236, Learning Rate: 0.0001\n",
            "Epoch 12/15, Loss: 0.20079057027235667, Learning Rate: 0.0001\n",
            "Epoch 13/15, Loss: 0.1869887159732373, Learning Rate: 0.0001\n",
            "Epoch 14/15, Loss: 0.17438305009994895, Learning Rate: 0.0001\n",
            "Epoch 15/15, Loss: 0.16958364128085124, Learning Rate: 0.0001\n",
            "Accuracy of the model on the test images: 89.57%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# CIFAR-10 데이터셋에 맞춘 데이터 전처리 및 로드\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize images to [-1, 1]\n",
        "])\n",
        "\n",
        "training_data = CIFAR10(root=\"./\", train=True, download=True, transform=transform)\n",
        "test_data = CIFAR10(root=\"./\", train=False, download=True, transform=transform)\n",
        "\n",
        "# 검증 세트를 위해 데이터 분할\n",
        "train_size = int(0.8 * len(training_data))\n",
        "val_size = len(training_data) - train_size\n",
        "train_data, val_data = random_split(training_data, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=64, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
        "\n",
        "# BasicBlock 및 ResNet 모델 정의\n",
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.c1 = nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)  # 배치 정규화 추가\n",
        "        self.c2 = nn.Conv2d(out_channels, out_channels, kernel_size, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)  # 배치 정규화 추가\n",
        "        self.relu = nn.ReLU()\n",
        "        self.downsample = None\n",
        "        if in_channels != out_channels:\n",
        "            self.downsample = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1)\n",
        "            self.bn_downsample = nn.BatchNorm2d(out_channels)  # 배치 정규화 추가\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_ = x\n",
        "        x = self.c1(x)\n",
        "        x = self.bn1(x)  # 배치 정규화 적용\n",
        "        x = self.relu(x)\n",
        "        x = self.c2(x)\n",
        "        x = self.bn2(x)  # 배치 정규화 적용\n",
        "        if self.downsample is not None:\n",
        "            x_ = self.downsample(x_)\n",
        "            x_ = self.bn_downsample(x_)  # 배치 정규화 적용\n",
        "        x += x_\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.b1 = block(in_channels=3, out_channels=64)  # CIFAR-10 이미지는 3 채널(RGB)\n",
        "        self.b2 = block(in_channels=64, out_channels=128)  # 레이어 2에 추가된 블록\n",
        "        self.b3 = block(in_channels=128, out_channels=128)  # 레이어 2에 추가된 블록\n",
        "        self.b4 = block(in_channels=128, out_channels=256)  # 레이어 3에 추가된 블록\n",
        "        self.b5 = block(in_channels=256, out_channels=256)  # 레이어 3에 추가된 블록\n",
        "        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(256 * 4 * 4, 512)  # CIFAR-10 이미지 크기(32x32)에 따라 수정 필요\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.b1(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.b2(x)  # 레이어 2에서 추가된 블록\n",
        "        x = self.b3(x)  # 레이어 2에서 추가된 블록\n",
        "        x = self.pool(x)\n",
        "        x = self.b4(x)  # 레이어 3에서 추가된 블록\n",
        "        x = self.b5(x)  # 레이어 3에서 추가된 블록\n",
        "        x = self.pool(x)\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# 학습 설정\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = ResNet(block=BasicBlock)\n",
        "model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)  # 스케줄러 초기화\n",
        "\n",
        "epochs = 50\n",
        "early_stopping_patience = 5  # 조기 종료를 위한 patience 설정\n",
        "best_val_loss = float('inf')\n",
        "patience_counter = 0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # 학습률 업데이트\n",
        "    scheduler.step()\n",
        "\n",
        "    # 현재 학습률 출력\n",
        "    current_lr = scheduler.get_last_lr()[0]\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader)}, Learning Rate: {current_lr}\")\n",
        "\n",
        "    # 검증 손실 계산\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "    val_loss /= len(val_loader)\n",
        "    print(f\"Validation Loss: {val_loss}\")\n",
        "\n",
        "    # 조기 종료 체크\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        patience_counter = 0\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= early_stopping_patience:\n",
        "            print(\"Early stop\")\n",
        "            break\n",
        "\n",
        "# 모델 평가\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Test Data Set 에 대한 정확도 : {100 * correct / total}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4E-gdcBLZ2QO",
        "outputId": "b4868dbe-390f-4fd1-ac33-7c7d5c70e404"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Epoch 1/50, Loss: 1.58576313495636, Learning Rate: 0.001\n",
            "Validation Loss: 1.3181641568803484\n",
            "Epoch 2/50, Loss: 1.1296372283935547, Learning Rate: 0.001\n",
            "Validation Loss: 1.1049794774905892\n",
            "Epoch 3/50, Loss: 0.920072786808014, Learning Rate: 0.001\n",
            "Validation Loss: 0.9043255987440705\n",
            "Epoch 4/50, Loss: 0.7892932816505432, Learning Rate: 0.001\n",
            "Validation Loss: 0.7796495300569352\n",
            "Epoch 5/50, Loss: 0.6831730722427368, Learning Rate: 0.001\n",
            "Validation Loss: 0.7220542996552339\n",
            "Epoch 6/50, Loss: 0.5999268781661987, Learning Rate: 0.001\n",
            "Validation Loss: 0.6284308739148887\n",
            "Epoch 7/50, Loss: 0.5286332146167755, Learning Rate: 0.001\n",
            "Validation Loss: 0.666615941911746\n",
            "Epoch 8/50, Loss: 0.4825626493930817, Learning Rate: 0.001\n",
            "Validation Loss: 0.6219275234990819\n",
            "Epoch 9/50, Loss: 0.435556382060051, Learning Rate: 0.001\n",
            "Validation Loss: 0.5400873728238853\n",
            "Epoch 10/50, Loss: 0.39946982429027555, Learning Rate: 0.0001\n",
            "Validation Loss: 0.47587904903539424\n",
            "Epoch 11/50, Loss: 0.27916781146526337, Learning Rate: 0.0001\n",
            "Validation Loss: 0.37771378144337114\n",
            "Epoch 12/50, Loss: 0.2414750228047371, Learning Rate: 0.0001\n",
            "Validation Loss: 0.37019873035561507\n",
            "Epoch 13/50, Loss: 0.2294262270271778, Learning Rate: 0.0001\n",
            "Validation Loss: 0.37461892728972584\n",
            "Epoch 14/50, Loss: 0.21624530124664307, Learning Rate: 0.0001\n",
            "Validation Loss: 0.360962389048877\n",
            "Epoch 15/50, Loss: 0.2051605811357498, Learning Rate: 0.0001\n",
            "Validation Loss: 0.3656113405421281\n",
            "Epoch 16/50, Loss: 0.1978734873354435, Learning Rate: 0.0001\n",
            "Validation Loss: 0.36588587085152885\n",
            "Epoch 17/50, Loss: 0.18716555534899235, Learning Rate: 0.0001\n",
            "Validation Loss: 0.36107880408596843\n",
            "Epoch 18/50, Loss: 0.17655413749217988, Learning Rate: 0.0001\n",
            "Validation Loss: 0.3745170210482209\n",
            "Epoch 19/50, Loss: 0.1732095088660717, Learning Rate: 0.0001\n",
            "Validation Loss: 0.36330498978021036\n",
            "Early stop\n",
            "Test Data Set 에 대한 정확도 : 88.64%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "\n",
        "# CIFAR-10 데이터셋에 맞춘 데이터 전처리 및 로드\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize images to [-1, 1]\n",
        "])\n",
        "\n",
        "training_data = CIFAR10(root=\"./\", train=True, download=True, transform=transform)\n",
        "\n",
        "# 데이터를 훈련용과 검증용으로 나누기\n",
        "train_ratio = 0.8\n",
        "train_size = int(train_ratio * len(training_data))\n",
        "val_size = len(training_data) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(training_data, [train_size, val_size])\n",
        "\n",
        "test_data = CIFAR10(root=\"./\", train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
        "\n",
        "# BasicBlock 및 ResNet 모델 정의\n",
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.c1 = nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=1)\n",
        "        self.c2 = nn.Conv2d(out_channels, out_channels, kernel_size, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.downsample = None\n",
        "        if in_channels != out_channels:\n",
        "            self.downsample = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_ = x\n",
        "        x = self.c1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.c2(x)\n",
        "        x = self.bn2(x)\n",
        "        if self.downsample is not None:\n",
        "            x_ = self.downsample(x_)\n",
        "        x += x_\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.b1 = block(in_channels=3, out_channels=64)  # CIFAR-10 이미지는 3 채널(RGB)\n",
        "        self.b2 = block(in_channels=64, out_channels=128)\n",
        "        self.b3 = block(in_channels=128, out_channels=256)\n",
        "        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(256 * 4 * 4, 512)  # CIFAR-10 이미지 크기(32x32)에 따라 수정 필요\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.b1(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.b2(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.b3(x)\n",
        "        x = self.pool(x)\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# 학습 설정\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = ResNet(block=BasicBlock)\n",
        "model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)  # 스케줄러 초기화\n",
        "\n",
        "# Early Stopping 관련 변수 초기화\n",
        "early_stop_patience = 5  # 최소한 early stopping을 위한 patience 설정\n",
        "best_val_loss = float('inf')\n",
        "patience_counter = 0\n",
        "\n",
        "# 학습 루프\n",
        "epochs = 50  # 에폭 수 설정\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # 학습률 업데이트\n",
        "    scheduler.step()\n",
        "\n",
        "    # 현재 학습률 출력\n",
        "    current_lr = scheduler.get_last_lr()[0]\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, \\n Loss: {running_loss/len(train_loader)}, \\n Learning Rate: {current_lr}\")\n",
        "\n",
        "    # 검증 데이터로 평가\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "    val_loss /= len(val_loader)\n",
        "    print(f\"검증 loss 값 : {val_loss}\")  # 검증 데이터의 손실 출력\n",
        "\n",
        "    # Early stopping 조건 체크\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        patience_counter = 0\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= early_stop_patience:\n",
        "            print(\"Early stopping\")\n",
        "            break\n",
        "\n",
        "# 최종 모델 평가\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"\\n 정확도 : {100 * correct / total}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cr4yiUCqjeT9",
        "outputId": "ae82c096-fdca-4a39-f76c-8384eaccafb1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Epoch 1/50, \n",
            " Loss: 1.4161937278747558, \n",
            " Learning Rate: 0.001\n",
            "검증 loss 값 : 1.141877902541191\n",
            "Epoch 2/50, \n",
            " Loss: 0.9813860609054565, \n",
            " Learning Rate: 0.001\n",
            "검증 loss 값 : 0.9116458627069073\n",
            "Epoch 3/50, \n",
            " Loss: 0.7732632119655609, \n",
            " Learning Rate: 0.001\n",
            "검증 loss 값 : 0.7430894031266498\n",
            "Epoch 4/50, \n",
            " Loss: 0.6379138450145722, \n",
            " Learning Rate: 0.001\n",
            "검증 loss 값 : 0.6279040893931298\n",
            "Epoch 5/50, \n",
            " Loss: 0.5416614319801331, \n",
            " Learning Rate: 0.001\n",
            "검증 loss 값 : 0.6218080256774927\n",
            "Epoch 6/50, \n",
            " Loss: 0.48078493552207946, \n",
            " Learning Rate: 0.001\n",
            "검증 loss 값 : 0.5712955138485902\n",
            "Epoch 7/50, \n",
            " Loss: 0.43017313640117644, \n",
            " Learning Rate: 0.001\n",
            "검증 loss 값 : 0.5432967386048311\n",
            "Epoch 8/50, \n",
            " Loss: 0.383597461605072, \n",
            " Learning Rate: 0.001\n",
            "검증 loss 값 : 0.49837368859606945\n",
            "Epoch 9/50, \n",
            " Loss: 0.34426924291849137, \n",
            " Learning Rate: 0.001\n",
            "검증 loss 값 : 0.4938453763343726\n",
            "Epoch 10/50, \n",
            " Loss: 0.3221910993218422, \n",
            " Learning Rate: 0.0001\n",
            "검증 loss 값 : 0.47539812051186897\n",
            "Epoch 11/50, \n",
            " Loss: 0.21813181401491166, \n",
            " Learning Rate: 0.0001\n",
            "검증 loss 값 : 0.37595247909141954\n",
            "Epoch 12/50, \n",
            " Loss: 0.18888017975091934, \n",
            " Learning Rate: 0.0001\n",
            "검증 loss 값 : 0.3693319694346683\n",
            "Epoch 13/50, \n",
            " Loss: 0.1764174390554428, \n",
            " Learning Rate: 0.0001\n",
            "검증 loss 값 : 0.36047538550226554\n",
            "Epoch 14/50, \n",
            " Loss: 0.16316365287303924, \n",
            " Learning Rate: 0.0001\n",
            "검증 loss 값 : 0.37244709846889895\n",
            "Epoch 15/50, \n",
            " Loss: 0.15271658852100373, \n",
            " Learning Rate: 0.0001\n",
            "검증 loss 값 : 0.37712366874240766\n",
            "Epoch 16/50, \n",
            " Loss: 0.14519843285232784, \n",
            " Learning Rate: 0.0001\n",
            "검증 loss 값 : 0.3697362143048056\n",
            "Epoch 17/50, \n",
            " Loss: 0.1401064611017704, \n",
            " Learning Rate: 0.0001\n",
            "검증 loss 값 : 0.36112741774814144\n",
            "Epoch 18/50, \n",
            " Loss: 0.13297639861106872, \n",
            " Learning Rate: 0.0001\n",
            "검증 loss 값 : 0.36840230164824017\n",
            "Early stopping\n",
            "\n",
            " 정확도 : 88.4%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zz8B6oaBkYkV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}